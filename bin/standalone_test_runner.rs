//! å®Œå…¨ç‹¬ç«‹çš„æµ‹è¯•å¯æ‰§è¡Œæ–‡ä»¶
//! ç”¨äºéªŒè¯æµ‹è¯•åŸºç¡€è®¾æ–½å’ŒåŸºæœ¬åŠŸèƒ½
//! ä¸ä¾èµ–äºé¡¹ç›®çš„lib.rs

use std::collections::HashMap;
use chrono::{DateTime, Utc, NaiveDate};
use serde::{Serialize, Deserialize};
use rand::Rng;

/// æµ‹è¯•ç”¨çš„ç®€åŒ–æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestUsageRecord {
    pub id: String,
    pub timestamp: DateTime<Utc>,
    pub model: String,
    pub input_tokens: u32,
    pub output_tokens: u32,
    pub cost: f64,
    pub session_id: Option<String>,
    pub user_id: Option<String>,
    pub metadata: HashMap<String, serde_json::Value>,
}

impl TestUsageRecord {
    pub fn new(
        timestamp: DateTime<Utc>,
        model: String,
        input_tokens: u32,
        output_tokens: u32,
        cost: f64,
    ) -> Self {
        Self {
            id: uuid::Uuid::new_v4().to_string(),
            timestamp,
            model,
            input_tokens,
            output_tokens,
            cost,
            session_id: None,
            user_id: None,
            metadata: HashMap::new(),
        }
    }
}

/// æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨
pub struct TestDataGenerator {
    rng: rand::rngs::ThreadRng,
}

impl TestDataGenerator {
    pub fn new() -> Self {
        Self {
            rng: rand::thread_rng(),
        }
    }
    
    /// ç”Ÿæˆæµ‹è¯•ä½¿ç”¨è®°å½•
    pub fn generate_usage_record(&mut self) -> TestUsageRecord {
        let start_date = NaiveDate::from_ymd_opt(2024, 1, 1).unwrap();
        let date = start_date + chrono::Duration::days(self.rng.gen_range(0..365));
        let timestamp = date.and_hms_opt(12, 0, 0).unwrap().and_utc();
        
        let models = ["claude-3-sonnet", "claude-3-opus", "claude-3-haiku"];
        let model = models[self.rng.gen_range(0..models.len())].to_string();
        
        let input_tokens = self.rng.gen_range(100..10000);
        let output_tokens = self.rng.gen_range(100..5000);
        let cost = (input_tokens + output_tokens) as f64 * 0.002;
        
        TestUsageRecord::new(timestamp, model, input_tokens, output_tokens, cost)
    }
    
    /// ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
    pub fn generate_large_dataset(&mut self, size: usize) -> Vec<TestUsageRecord> {
        (0..size).map(|_| self.generate_usage_record()).collect()
    }
}

/// æµ‹è¯•å·¥å…·å‡½æ•°
pub mod test_utils {
    use super::*;
    use std::time::Instant;
    
    /// æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´
    pub fn measure_execution_time<F, R>(f: F) -> (R, std::time::Duration)
    where
        F: FnOnce() -> R,
    {
        let start = Instant::now();
        let result = f();
        let duration = start.elapsed();
        (result, duration)
    }
    
    /// åˆ›å»ºä¸´æ—¶ç›®å½•
    pub fn create_temp_dir() -> tempfile::TempDir {
        tempfile::TempDir::new().expect("Failed to create temporary directory")
    }
    
    /// éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
    pub fn validate_usage_record(record: &TestUsageRecord) -> bool {
        !record.id.is_empty()
            && !record.model.is_empty()
            && record.input_tokens > 0
            && record.output_tokens > 0
            && record.cost > 0.0
    }
}

/// æ€§èƒ½æµ‹è¯•å·¥å…·
pub mod performance_utils {
    use super::*;
    
    /// æµ‹è¯•æ•°æ®ç”Ÿæˆæ€§èƒ½
    pub fn benchmark_data_generation(size: usize) -> std::time::Duration {
        let mut generator = TestDataGenerator::new();
        let (_, duration) = test_utils::measure_execution_time(|| {
            generator.generate_large_dataset(size)
        });
        duration
    }
    
    /// æµ‹è¯•åºåˆ—åŒ–æ€§èƒ½
    pub fn benchmark_serialization(data: &[TestUsageRecord]) -> std::time::Duration {
        let (_, duration) = test_utils::measure_execution_time(|| {
            serde_json::to_string(data)
        });
        duration
    }
    
    /// æµ‹è¯•è¿‡æ»¤æ€§èƒ½
    pub fn benchmark_filtering(data: &[TestUsageRecord], cost_threshold: f64) -> std::time::Duration {
        let (_, duration) = test_utils::measure_execution_time(|| {
            data.iter()
                .filter(|record| record.cost > cost_threshold)
                .count()
        });
        duration
    }
    
    /// æµ‹è¯•æ’åºæ€§èƒ½
    pub fn benchmark_sorting(data: &mut [TestUsageRecord]) -> std::time::Duration {
        let (_, duration) = test_utils::measure_execution_time(|| {
            data.sort_by(|a, b| b.cost.partial_cmp(&a.cost).unwrap());
        });
        duration
    }
    
    /// æµ‹è¯•èšåˆæ€§èƒ½
    pub fn benchmark_aggregation(data: &[TestUsageRecord]) -> std::time::Duration {
        let (_, duration) = test_utils::measure_execution_time(|| {
            let mut model_stats = HashMap::new();
            for record in data {
                let entry = model_stats.entry(&record.model).or_insert((0u64, 0.0));
                entry.0 += (record.input_tokens + record.output_tokens) as u64;
                entry.1 += record.cost;
            }
            model_stats
        });
        duration
    }
}

/// æµ‹è¯•ç»“æœ
#[derive(Debug)]
pub struct TestResult {
    pub test_name: String,
    pub passed: bool,
    pub duration: std::time::Duration,
    pub message: String,
}

/// æ€§èƒ½æŒ‡æ ‡
#[derive(Debug)]
pub struct PerformanceMetrics {
    pub data_generation_time: std::time::Duration,
    pub serialization_time: std::time::Duration,
    pub filtering_time: std::time::Duration,
    pub sorting_time: std::time::Duration,
    pub aggregation_time: std::time::Duration,
}

/// æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå™¨
pub struct TestReport {
    pub test_results: Vec<TestResult>,
    pub performance_metrics: PerformanceMetrics,
}

impl TestReport {
    pub fn new() -> Self {
        Self {
            test_results: Vec::new(),
            performance_metrics: PerformanceMetrics {
                data_generation_time: std::time::Duration::from_secs(0),
                serialization_time: std::time::Duration::from_secs(0),
                filtering_time: std::time::Duration::from_secs(0),
                sorting_time: std::time::Duration::from_secs(0),
                aggregation_time: std::time::Duration::from_secs(0),
            },
        }
    }
    
    pub fn add_test_result(&mut self, result: TestResult) {
        self.test_results.push(result);
    }
    
    pub fn set_performance_metrics(&mut self, metrics: PerformanceMetrics) {
        self.performance_metrics = metrics;
    }
    
    pub fn generate_report(&self) -> String {
        let mut report = String::new();
        
        report.push_str("=== ccusage-rs æµ‹è¯•æŠ¥å‘Š ===\n\n");
        
        // æµ‹è¯•ç»“æœç»Ÿè®¡
        let passed_tests = self.test_results.iter().filter(|r| r.passed).count();
        let total_tests = self.test_results.len();
        
        report.push_str(&format!("æµ‹è¯•ç»“æœ: {}/{} é€šè¿‡\n", passed_tests, total_tests));
        report.push_str(&format!("æˆåŠŸç‡: {:.1}%\n\n", 
                                (passed_tests as f64 / total_tests as f64) * 100.0));
        
        // è¯¦ç»†æµ‹è¯•ç»“æœ
        report.push_str("è¯¦ç»†æµ‹è¯•ç»“æœ:\n");
        for result in &self.test_results {
            let status = if result.passed { "âœ…" } else { "âŒ" };
            report.push_str(&format!("{} {} ({:?}) - {}\n", 
                                    status, result.test_name, result.duration, result.message));
        }
        
        // æ€§èƒ½æŒ‡æ ‡
        report.push_str("\n=== æ€§èƒ½æŒ‡æ ‡ ===\n");
        report.push_str(&format!("æ•°æ®ç”Ÿæˆæ—¶é—´: {:?}\n", self.performance_metrics.data_generation_time));
        report.push_str(&format!("åºåˆ—åŒ–æ—¶é—´: {:?}\n", self.performance_metrics.serialization_time));
        report.push_str(&format!("è¿‡æ»¤æ—¶é—´: {:?}\n", self.performance_metrics.filtering_time));
        report.push_str(&format!("æ’åºæ—¶é—´: {:?}\n", self.performance_metrics.sorting_time));
        report.push_str(&format!("èšåˆæ—¶é—´: {:?}\n", self.performance_metrics.aggregation_time));
        
        report
    }
}

/// è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
pub fn run_test_suite() -> TestReport {
    let mut report = TestReport::new();
    let mut generator = TestDataGenerator::new();
    
    println!("ğŸš€ å¼€å§‹è¿è¡Œ ccusage-rs æµ‹è¯•å¥—ä»¶...\n");
    
    // 1. åŸºç¡€åŠŸèƒ½æµ‹è¯•
    println!("ğŸ“‹ è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•...");
    let start_time = std::time::Instant::now();
    
    // æµ‹è¯•æ•°æ®åˆ›å»º
    let record = TestUsageRecord::new(
        Utc::now(),
        "claude-3-sonnet".to_string(),
        1000,
        500,
        3.0,
    );
    
    let basic_test_passed = !record.id.is_empty()
        && record.model == "claude-3-sonnet"
        && record.input_tokens == 1000
        && record.output_tokens == 500
        && record.cost == 3.0;
    
    report.add_test_result(TestResult {
        test_name: "basic_data_creation".to_string(),
        passed: basic_test_passed,
        duration: start_time.elapsed(),
        message: "åŸºç¡€æ•°æ®åˆ›å»ºæµ‹è¯•".to_string(),
    });
    
    // 2. æ•°æ®ç”Ÿæˆå™¨æµ‹è¯•
    println!("ğŸ”„ æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨...");
    let start_time = std::time::Instant::now();
    let test_record = generator.generate_usage_record();
    let generator_test_passed = test_utils::validate_usage_record(&test_record);
    
    report.add_test_result(TestResult {
        test_name: "data_generator".to_string(),
        passed: generator_test_passed,
        duration: start_time.elapsed(),
        message: "æ•°æ®ç”Ÿæˆå™¨åŠŸèƒ½æµ‹è¯•".to_string(),
    });
    
    // 3. å¤§æ•°æ®é›†æµ‹è¯•
    println!("ğŸ“Š æµ‹è¯•å¤§æ•°æ®é›†ç”Ÿæˆ...");
    let start_time = std::time::Instant::now();
    let large_dataset = generator.generate_large_dataset(1000);
    let dataset_test_passed = large_dataset.len() == 1000 
        && large_dataset.iter().all(|r| test_utils::validate_usage_record(r));
    
    report.add_test_result(TestResult {
        test_name: "large_dataset_generation".to_string(),
        passed: dataset_test_passed,
        duration: start_time.elapsed(),
        message: format!("ç”Ÿæˆäº† {} æ¡è®°å½•", large_dataset.len()),
    });
    
    // 4. åºåˆ—åŒ–æµ‹è¯•
    println!("ğŸ’¾ æµ‹è¯•åºåˆ—åŒ–åŠŸèƒ½...");
    let start_time = std::time::Instant::now();
    let json_data = serde_json::to_string(&large_dataset).unwrap();
    let deserialized: Vec<TestUsageRecord> = serde_json::from_str(&json_data).unwrap();
    let serialization_test_passed = deserialized.len() == large_dataset.len();
    
    report.add_test_result(TestResult {
        test_name: "serialization".to_string(),
        passed: serialization_test_passed,
        duration: start_time.elapsed(),
        message: format!("åºåˆ—åŒ–æ•°æ®å¤§å°: {} bytes", json_data.len()),
    });
    
    // 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
    println!("âš¡ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...");
    let performance_start = std::time::Instant::now();
    
    // æ•°æ®ç”Ÿæˆæ€§èƒ½
    let data_gen_duration = performance_utils::benchmark_data_generation(5000);
    
    // åºåˆ—åŒ–æ€§èƒ½
    let serialize_duration = performance_utils::benchmark_serialization(&large_dataset);
    
    // è¿‡æ»¤æ€§èƒ½
    let filter_duration = performance_utils::benchmark_filtering(&large_dataset, 5.0);
    
    // æ’åºæ€§èƒ½
    let mut data_for_sort = large_dataset.clone();
    let sort_duration = performance_utils::benchmark_sorting(&mut data_for_sort);
    
    // èšåˆæ€§èƒ½
    let agg_duration = performance_utils::benchmark_aggregation(&large_dataset);
    
    let performance_test_passed = data_gen_duration < std::time::Duration::from_millis(500)
        && serialize_duration < std::time::Duration::from_millis(100)
        && filter_duration < std::time::Duration::from_millis(10)
        && sort_duration < std::time::Duration::from_millis(50)
        && agg_duration < std::time::Duration::from_millis(20);
    
    report.add_test_result(TestResult {
        test_name: "performance_benchmarks".to_string(),
        passed: performance_test_passed,
        duration: performance_start.elapsed(),
        message: "æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ".to_string(),
    });
    
    // è®¾ç½®æ€§èƒ½æŒ‡æ ‡
    report.set_performance_metrics(PerformanceMetrics {
        data_generation_time: data_gen_duration,
        serialization_time: serialize_duration,
        filtering_time: filter_duration,
        sorting_time: sort_duration,
        aggregation_time: agg_duration,
    });
    
    // 6. å†…å­˜ä½¿ç”¨æµ‹è¯•
    println!("ğŸ§  æµ‹è¯•å†…å­˜ä½¿ç”¨...");
    let start_time = std::time::Instant::now();
    let memory_test_data = generator.generate_large_dataset(10000);
    let estimated_memory = memory_test_data.len() * std::mem::size_of::<TestUsageRecord>();
    let memory_test_passed = estimated_memory > 0 && memory_test_data.len() == 10000;
    
    report.add_test_result(TestResult {
        test_name: "memory_usage".to_string(),
        passed: memory_test_passed,
        duration: start_time.elapsed(),
        message: format!("ä¼°ç®—å†…å­˜ä½¿ç”¨: {} bytes", estimated_memory),
    });
    
    // 7. å¹¶å‘å¤„ç†æµ‹è¯•
    println!("ğŸ”€ æµ‹è¯•å¹¶å‘å¤„ç†...");
    let start_time = std::time::Instant::now();
    let concurrent_data = generator.generate_large_dataset(10000);
    
    use std::thread;
    use std::sync::Arc;
    
    let data_arc = Arc::new(concurrent_data.clone());
    let chunk_size = data_arc.len() / 4;
    
    let handles: Vec<_> = (0..4)
        .map(|i| {
            let data_clone = data_arc.clone();
            let start = i * chunk_size;
            let end = if i == 3 { data_clone.len() } else { start + chunk_size };
            
            thread::spawn(move || {
                data_clone[start..end]
                    .iter()
                    .filter(|record| record.input_tokens + record.output_tokens > 5000)
                    .count()
            })
        })
        .collect();
    
    let concurrent_result: usize = handles.into_iter().map(|h| h.join().unwrap()).sum();
    let expected_count = concurrent_data.iter()
        .filter(|record| record.input_tokens + record.output_tokens > 5000)
        .count();
    
    let concurrent_test_passed = concurrent_result == expected_count;
    
    report.add_test_result(TestResult {
        test_name: "concurrent_processing".to_string(),
        passed: concurrent_test_passed,
        duration: start_time.elapsed(),
        message: format!("å¹¶å‘å¤„ç†ç»“æœ: {} / {}", concurrent_result, expected_count),
    });
    
    // 8. ç»¼åˆå·¥ä½œæµæµ‹è¯•
    println!("ğŸ”„ è¿è¡Œç»¼åˆå·¥ä½œæµæµ‹è¯•...");
    let start_time = std::time::Instant::now();
    
    // å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹
    let workflow_data = generator.generate_large_dataset(2000);
    
    // è¿‡æ»¤é«˜æˆæœ¬è®°å½•
    let high_cost_records: Vec<_> = workflow_data.iter()
        .filter(|record| record.cost > 3.0)
        .cloned()
        .collect();
    
    // æŒ‰æ¨¡å‹èšåˆ
    let model_costs: HashMap<_, _> = high_cost_records
        .iter()
        .map(|record| (&record.model, record.cost))
        .fold(HashMap::new(), |mut acc, (model, cost)| {
            *acc.entry(model).or_insert(0.0) += cost;
            acc
        });
    
    // æ’åº
    let mut sorted_models: Vec<_> = model_costs.into_iter().collect();
    sorted_models.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    
    let workflow_test_passed = !sorted_models.is_empty() && sorted_models.len() <= 3; // æœ€å¤š3ä¸ªæ¨¡å‹
    
    report.add_test_result(TestResult {
        test_name: "comprehensive_workflow".to_string(),
        passed: workflow_test_passed,
        duration: start_time.elapsed(),
        message: format!("å¤„ç†äº† {} ä¸ªæ¨¡å‹çš„æ•°æ®", sorted_models.len()),
    });
    
    println!("\nğŸ“Š æµ‹è¯•å®Œæˆï¼ç”ŸæˆæŠ¥å‘Š...");
    report
}

fn main() {
    // è¿è¡Œæµ‹è¯•å¥—ä»¶
    let report = run_test_suite();
    
    // ç”Ÿæˆå¹¶è¾“å‡ºæŠ¥å‘Š
    let report_text = report.generate_report();
    println!("{}", report_text);
    
    // è¾“å‡ºæ€»ç»“
    let passed_tests = report.test_results.iter().filter(|r| r.passed).count();
    let total_tests = report.test_results.len();
    let success_rate = (passed_tests as f64 / total_tests as f64) * 100.0;
    
    println!("\nğŸ¯ æµ‹è¯•æ€»ç»“:");
    println!("   æ€»æµ‹è¯•æ•°: {}", total_tests);
    println!("   é€šè¿‡æµ‹è¯•: {}", passed_tests);
    println!("   æˆåŠŸç‡: {:.1}%", success_rate);
    
    if success_rate >= 80.0 {
        println!("âœ… æµ‹è¯•è¦†ç›–ç‡è¾¾æ ‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚");
        std::process::exit(0);
    } else {
        println!("âŒ æµ‹è¯•è¦†ç›–ç‡ä¸è¶³ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚");
        std::process::exit(1);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_report_generation() {
        let mut report = TestReport::new();
        
        report.add_test_result(TestResult {
            test_name: "test_example".to_string(),
            passed: true,
            duration: std::time::Duration::from_millis(10),
            message: "ç¤ºä¾‹æµ‹è¯•".to_string(),
        });
        
        let report_text = report.generate_report();
        assert!(report_text.contains("æµ‹è¯•ç»“æœ: 1/1 é€šè¿‡"));
        assert!(report_text.contains("test_example"));
    }
    
    #[test]
    fn test_data_validation() {
        let timestamp = Utc::now();
        let valid_record = TestUsageRecord::new(timestamp, "test".to_string(), 100, 50, 0.3);
        let invalid_record = TestUsageRecord::new(timestamp, "test".to_string(), 0, 0, 0.0);
        
        assert!(test_utils::validate_usage_record(&valid_record));
        assert!(!test_utils::validate_usage_record(&invalid_record));
    }
}