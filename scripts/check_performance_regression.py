#!/usr/bin/env python3
"""
æ€§èƒ½å›å½’æ£€æŸ¥è„šæœ¬
ç”¨äºæ¯”è¾ƒåŸºå‡†æµ‹è¯•ç»“æœï¼Œæ£€æµ‹æ€§èƒ½å›å½’
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import argparse

class PerformanceRegressionChecker:
    """æ€§èƒ½å›å½’æ£€æŸ¥å™¨"""
    
    def __init__(self, criterion_dir: str = "target/criterion"):
        self.criterion_dir = Path(criterion_dir)
        self.thresholds = {
            "time": 0.10,  # 10%çš„æ—¶é—´å›å½’é˜ˆå€¼
            "memory": 0.15,  # 15%çš„å†…å­˜å›å½’é˜ˆå€¼
        }
        
    def load_benchmark_results(self, benchmark_name: str) -> Dict[str, Any]:
        """åŠ è½½åŸºå‡†æµ‹è¯•ç»“æœ"""
        benchmark_dir = self.criterion_dir / benchmark_name / "new"
        if not benchmark_dir.exists():
            return {}
            
        # æŸ¥æ‰¾estimates.jsonæ–‡ä»¶
        estimates_file = benchmark_dir / "estimates.json"
        if not estimates_file.exists():
            return {}
            
        try:
            with open(estimates_file, 'r') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            return {}
    
    def compare_benchmarks(self, baseline_results: Dict[str, Any], 
                         current_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ¯”è¾ƒåŸºå‡†æµ‹è¯•ç»“æœ"""
        comparison = {
            "time_regression": False,
            "memory_regression": False,
            "time_change": 0.0,
            "memory_change": 0.0,
            "details": {}
        }
        
        # æ¯”è¾ƒæ‰§è¡Œæ—¶é—´
        if "Mean" in baseline_results and "Mean" in current_results:
            baseline_time = baseline_results["Mean"]["point_estimate"]
            current_time = current_results["Mean"]["point_estimate"]
            
            if baseline_time > 0:
                time_change = (current_time - baseline_time) / baseline_time
                comparison["time_change"] = time_change
                comparison["time_regression"] = time_change > self.thresholds["time"]
                
                comparison["details"]["time"] = {
                    "baseline": baseline_time,
                    "current": current_time,
                    "change_percent": time_change * 100,
                    "threshold": self.thresholds["time"] * 100
                }
        
        # æ¯”è¾ƒå†…å­˜ä½¿ç”¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if "memory" in baseline_results and "memory" in current_results:
            baseline_memory = baseline_results["memory"]["point_estimate"]
            current_memory = current_results["memory"]["point_estimate"]
            
            if baseline_memory > 0:
                memory_change = (current_memory - baseline_memory) / baseline_memory
                comparison["memory_change"] = memory_change
                comparison["memory_regression"] = memory_change > self.thresholds["memory"]
                
                comparison["details"]["memory"] = {
                    "baseline": baseline_memory,
                    "current": current_memory,
                    "change_percent": memory_change * 100,
                    "threshold": self.thresholds["memory"] * 100
                }
        
        return comparison
    
    def check_regressions(self) -> List[Dict[str, Any]]:
        """æ£€æŸ¥æ‰€æœ‰åŸºå‡†æµ‹è¯•çš„å›å½’"""
        regressions = []
        
        # è·å–æ‰€æœ‰åŸºå‡†æµ‹è¯•ç›®å½•
        benchmark_dirs = [d for d in self.criterion_dir.iterdir() 
                         if d.is_dir() and d.name != "base"]
        
        for benchmark_dir in benchmark_dirs:
            benchmark_name = benchmark_dir.name
            
            # åŠ è½½åŸºçº¿ç»“æœ
            baseline_results = self.load_benchmark_results(f"{benchmark_name}/base")
            if not baseline_results:
                continue
                
            # åŠ è½½å½“å‰ç»“æœ
            current_results = self.load_benchmark_results(benchmark_name)
            if not current_results:
                continue
                
            # æ¯”è¾ƒç»“æœ
            comparison = self.compare_benchmarks(baseline_results, current_results)
            
            # å¦‚æœæœ‰å›å½’ï¼Œæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            if comparison["time_regression"] or comparison["memory_regression"]:
                regressions.append({
                    "benchmark": benchmark_name,
                    "comparison": comparison
                })
        
        return regressions
    
    def generate_report(self, regressions: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå›å½’æŠ¥å‘Š"""
        if not regressions:
            return "âœ… æ²¡æœ‰æ£€æµ‹åˆ°æ€§èƒ½å›å½’"
        
        report = ["âš ï¸ æ£€æµ‹åˆ°æ€§èƒ½å›å½’ï¼š", ""]
        
        for regression in regressions:
            benchmark_name = regression["benchmark"]
            comparison = regression["comparison"]
            
            report.append(f"ğŸ“Š {benchmark_name}:")
            
            if comparison["time_regression"]:
                time_details = comparison["details"]["time"]
                report.append(f"  â±ï¸  æ—¶é—´å›å½’: +{time_details['change_percent']:.2f}% "
                             f"(é˜ˆå€¼: {time_details['threshold']:.1f}%)")
            
            if comparison["memory_regression"]:
                memory_details = comparison["details"]["memory"]
                report.append(f"  ğŸ’¾ å†…å­˜å›å½’: +{memory_details['change_percent']:.2f}% "
                             f"(é˜ˆå€¼: {memory_details['threshold']:.1f}%)")
            
            report.append("")
        
        return "\n".join(report)
    
    def check_and_report(self) -> bool:
        """æ£€æŸ¥å›å½’å¹¶è¿”å›æ˜¯å¦é€šè¿‡"""
        regressions = self.check_regressions()
        report = self.generate_report(regressions)
        
        print(report)
        
        # å¦‚æœæœ‰å›å½’ï¼Œè¿”å›å¤±è´¥
        return len(regressions) == 0

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ€§èƒ½å›å½’")
    parser.add_argument("--criterion-dir", default="target/criterion",
                       help="åŸºå‡†æµ‹è¯•ç»“æœç›®å½•")
    parser.add_argument("--time-threshold", type=float, default=0.10,
                       help="æ—¶é—´å›å½’é˜ˆå€¼ (é»˜è®¤: 0.10 = 10%)")
    parser.add_argument("--memory-threshold", type=float, default=0.15,
                       help="å†…å­˜å›å½’é˜ˆå€¼ (é»˜è®¤: 0.15 = 15%)")
    parser.add_argument("--json", action="store_true",
                       help="è¾“å‡ºJSONæ ¼å¼ç»“æœ")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = PerformanceRegressionChecker(args.criterion_dir)
    checker.thresholds["time"] = args.time_threshold
    checker.thresholds["memory"] = args.memory_threshold
    
    # æ£€æŸ¥å›å½’
    regressions = checker.check_regressions()
    
    if args.json:
        # JSONè¾“å‡º
        result = {
            "has_regressions": len(regressions) > 0,
            "regressions": regressions,
            "thresholds": checker.thresholds
        }
        print(json.dumps(result, indent=2))
    else:
        # æ–‡æœ¬è¾“å‡º
        report = checker.generate_report(regressions)
        print(report)
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    sys.exit(0 if len(regressions) == 0 else 1)

if __name__ == "__main__":
    main()